<div align="center">

<h1>Text2Performer: Text-Driven Human Video Generation</h1>

<div>
    <a href="https://yumingj.github.io/" target="_blank">Yuming Jiang</a><sup>1</sup>,
    <a href="https://williamyang1991.github.io/" target="_blank">Shuai Yang</a><sup>1</sup>,
    <a href="https://github.com/yumingj/Text2Performer">Tong Liang Koh</a><sup>1</sup>,
    <a href="https://wywu.github.io/" target="_blank">Wayne Wu</a><sup>2</sup>,
    <a href="https://www.mmlab-ntu.com/person/ccloy/" target="_blank">Chen Change Loy</a><sup>1</sup>,
    <a href="https://liuziwei7.github.io/" target="_blank">Ziwei Liu</a><sup>1</sup>
</div>
<div>
    <sup>1</sup>S-Lab, Nanyang Technological University&emsp; <sup>2</sup>Shanghai AI Laboratory
</div>

[Paper](https://arxiv.org/pdf/2304.08483.pdf) | [Project Page](https://yumingj.github.io/projects/Text2Performer.html) | [Video](https://youtu.be/YwhaJUk_qo0)
</br>

<strong>Text2Performer synthesizes human videos by taking the text descriptions as the only input.</strong>

<div style="width: 100%; text-align: center; margin:auto;">
    <img style="width:100%" src="img/teaser.png">
</div>

:open_book: For more visual results, go checkout our <a href="https://yumingj.github.io/projects/Text2Performer.html" target="_blank">project page</a>


## :newspaper_roll: License

Distributed under the S-Lab License. See `LICENSE` for more information.

![visitor badge](https://visitor-badge.glitch.me/badge?page_id=yumingj/Text2Performer&left_color=red&right_color=green&left_text=HelloVisitors)

